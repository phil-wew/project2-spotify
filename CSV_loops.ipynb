{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite://', echo=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features = pd.read_csv(r'Data/all_songs_data/data.csv')\n",
    "\n",
    "track_features = track_features.rename(columns={\"name\" : \"Track Name\", \"artists\" : \"Artist\"})\n",
    "\n",
    "track_features.loc[:,'Artist'] = track_features.Artist.map(lambda x: x.replace(\"['\", \"\").replace(\"']\",\"\"))\n",
    "                                                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n",
      "Index(['Position', 'Track Name', 'Artist', 'Streams', 'URL', 'Week', 'Region'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/global_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[35:45]\n",
    "    df = pd.read_csv('Data/global_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Global'\n",
    "    df.to_csv('Data/global_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(df.columns)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/global_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-ar-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-ar-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-ar-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-ar-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-ar-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-ar-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-ar-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-ar-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-ar-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-ar-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-ar-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-ar-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-ar-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-ar-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-ar-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-ar-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-ar-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-ar-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-ar-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-ar-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-ar-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-ar-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-ar-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-ar-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-ar-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-ar-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-ar-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-ar-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-ar-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-ar-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-ar-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-ar-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-ar-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-ar-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-ar-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-ar-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-ar-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-ar-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-ar-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-ar-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-ar-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-ar-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-ar-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-ar-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-ar-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-ar-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-ar-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-ar-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-ar-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-ar-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-ar-weekly-2019-11-08--2019-11-15.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/argentina_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/argentina_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Argentina'\n",
    "    df.to_csv('Data/argentina_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/argentina_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-at-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-at-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-at-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-at-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-at-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-at-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-at-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-at-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-at-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-at-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-at-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-at-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-at-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-at-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-at-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-at-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-at-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-at-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-at-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-at-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-at-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-at-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-at-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-at-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-at-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-at-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-at-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-at-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-at-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-at-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-at-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-at-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-at-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-at-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-at-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-at-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-at-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-at-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-at-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-at-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-at-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-at-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-at-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-at-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-at-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-at-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-at-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-at-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-at-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-at-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-at-weekly-2019-10-04--2019-10-11.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/austria_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/austria_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Austria'\n",
    "    df.to_csv('Data/austria_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/austria_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-be-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-be-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-be-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-be-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-be-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-be-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-be-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-be-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-be-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-be-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-be-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-be-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-be-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-be-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-be-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-be-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-be-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-be-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-be-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-be-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-be-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-be-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-be-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-be-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-be-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-be-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-be-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-be-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-be-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-be-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-be-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-be-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-be-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-be-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-be-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-be-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-be-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-be-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-be-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-be-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-be-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-be-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-be-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-be-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-be-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-be-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-be-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-be-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-be-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-be-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-be-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-be-weekly-2019-06-14--2019-06-21.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/belgium_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/belgium_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Belgium'\n",
    "    df.to_csv('Data/belgium_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/belgium_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-bo-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-bo-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-bo-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-bo-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-bo-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-bo-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-bo-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-bo-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-bo-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-bo-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-bo-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-bo-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-bo-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-bo-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-bo-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-bo-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-bo-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-bo-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-bo-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-bo-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-bo-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-bo-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-bo-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-bo-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-bo-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-bo-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-bo-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-bo-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-bo-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-bo-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-bo-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-bo-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-bo-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-bo-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-bo-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-bo-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-bo-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-bo-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-bo-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-bo-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-bo-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-bo-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-bo-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-bo-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-bo-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-bo-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-bo-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-bo-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-bo-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-bo-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-bo-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-bo-weekly-2019-10-04--2019-10-11.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/bolivia_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/bolivia_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Bolivia'\n",
    "    df.to_csv('Data/bolivia_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/bolivia_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-br-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-br-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-br-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-br-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-br-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-br-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-br-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-br-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-br-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-br-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-br-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-br-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-br-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-br-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-br-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-br-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-br-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-br-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-br-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-br-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-br-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-br-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-br-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-br-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-br-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-br-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-br-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-br-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-br-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-br-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-br-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-br-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-br-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-br-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-br-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-br-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-br-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-br-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-br-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-br-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-br-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-br-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-br-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-br-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-br-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-br-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-br-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-br-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-br-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-br-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-br-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-br-weekly-2019-10-18--2019-10-25.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/brazil_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/brazil_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Brazil'\n",
    "    df.to_csv('Data/brazil_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/brazil_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-ca-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-ca-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-ca-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-ca-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-ca-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-ca-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-ca-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-ca-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-ca-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-ca-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-ca-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-ca-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-ca-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-ca-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-ca-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-ca-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-ca-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-ca-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-ca-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-ca-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-ca-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-ca-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-ca-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-ca-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-ca-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-ca-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-ca-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-ca-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-ca-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-ca-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-ca-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-ca-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-ca-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-ca-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-ca-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-ca-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-ca-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-ca-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-ca-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-ca-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-ca-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-ca-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-ca-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-ca-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-ca-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-ca-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-ca-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-ca-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-ca-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-ca-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-ca-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-ca-weekly-2019-03-29--2019-04-05.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/canada_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/canada_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Canada'\n",
    "    df.to_csv('Data/canada_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/canada_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-cl-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-cl-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-cl-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-cl-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-cl-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-cl-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-cl-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-cl-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-cl-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-cl-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-cl-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-cl-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-cl-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-cl-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-cl-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-cl-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-cl-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-cl-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-cl-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-cl-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-cl-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-cl-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-cl-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-cl-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-cl-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-cl-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-cl-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-cl-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-cl-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-cl-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-cl-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-cl-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-cl-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-cl-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-cl-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-cl-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-cl-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-cl-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-cl-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-cl-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-cl-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-cl-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-cl-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-cl-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-cl-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-cl-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-cl-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-cl-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-cl-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-cl-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-cl-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-cl-weekly-2019-12-20--2019-12-27.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/chile_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/chile_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Chile'\n",
    "    df.to_csv('Data/chile_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/chile_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-co-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-co-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-co-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-co-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-co-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-co-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-co-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-co-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-co-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-co-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-co-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-co-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-co-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-co-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-co-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-co-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-co-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-co-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-co-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-co-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-co-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-co-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-co-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-co-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-co-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-co-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-co-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-co-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-co-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-co-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-co-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-co-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-co-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-co-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-co-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-co-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-co-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-co-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-co-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-co-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-co-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-co-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-co-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-co-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-co-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-co-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-co-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-co-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-co-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-co-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-co-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-co-weekly-2019-01-04--2019-01-11.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/colombia_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/colombia_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Colombia'\n",
    "    df.to_csv('Data/colombia_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/colombia_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames = [i for i in os.listdir('Data/france_weekly_charts') if \".csv\" in i]\n",
    "# alldata = pd.DataFrame()\n",
    "\n",
    "# for i in filenames:\n",
    "#     date = i[31:41]\n",
    "#     df = pd.read_csv('Data/france_weekly_charts/' + i, header = 1)\n",
    "#     df.loc[:,'Week']= date\n",
    "#     df.loc[:,'Region'] = 'France'\n",
    "#     df.to_csv('Data/france_weekly_charts/' + i, index = False)\n",
    "    \n",
    "#     #Now accumulate to master file\n",
    "#     alldata = pd.concat((alldata, df))\n",
    "#     print(i)\n",
    "\n",
    "# alldata.to_csv('Data/all_weekly_charts/france_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-gb-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-gb-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-gb-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-gb-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-gb-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-gb-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-gb-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-gb-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-gb-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-gb-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-gb-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-gb-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-gb-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-gb-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-gb-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-gb-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-gb-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-gb-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-gb-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-gb-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-gb-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-gb-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-gb-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-gb-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-gb-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-gb-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-gb-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-gb-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-gb-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-gb-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-gb-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-gb-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-gb-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-gb-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-gb-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-gb-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-gb-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-gb-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-gb-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-gb-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-gb-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-gb-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-gb-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-gb-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-gb-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-gb-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-gb-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-gb-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-gb-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-gb-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-gb-weekly-2019-09-13--2019-09-20.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/GB_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/GB_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Great Britain'\n",
    "    df.to_csv('Data/GB_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/GB_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-us-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-us-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-us-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-us-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-us-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-us-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-us-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-us-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-us-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-us-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-us-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-us-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-us-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-us-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-us-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-us-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-us-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-us-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-us-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-us-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-us-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-us-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-us-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-us-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-us-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-us-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-us-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-us-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-us-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-us-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-us-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-us-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-us-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-us-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-us-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-us-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-us-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-us-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-us-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-us-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-us-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-us-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-us-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-us-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-us-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-us-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-us-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-us-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-us-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-us-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-us-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-us-weekly-2019-12-20--2019-12-27.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/US_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/US_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'United States of America'\n",
    "    df.to_csv('Data/US_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/US_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-bg-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-bg-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-bg-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-bg-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-bg-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-bg-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-bg-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-bg-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-bg-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-bg-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-bg-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-bg-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-bg-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-bg-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-bg-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-bg-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-bg-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-bg-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-bg-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-bg-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-bg-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-bg-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-bg-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-bg-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-bg-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-bg-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-bg-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-bg-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-bg-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-bg-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-bg-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-bg-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-bg-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-bg-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-bg-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-bg-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-bg-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-bg-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-bg-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-bg-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-bg-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-bg-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-bg-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-bg-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-bg-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-bg-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-bg-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-bg-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-bg-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-bg-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-bg-weekly-2019-09-27--2019-10-04.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/bulgaria_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/bulgaria_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Bulgaria'\n",
    "    df.to_csv('Data/bulgaria_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/bulgaria_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-ch-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-ch-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-ch-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-ch-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-ch-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-ch-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-ch-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-ch-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-ch-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-ch-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-ch-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-ch-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-ch-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-ch-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-ch-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-ch-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-ch-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-ch-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-ch-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-ch-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-ch-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-ch-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-ch-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-ch-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-ch-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-ch-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-ch-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-ch-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-ch-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-ch-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-ch-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-ch-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-ch-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-ch-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-ch-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-ch-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-ch-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-ch-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-ch-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-ch-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-ch-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-ch-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-ch-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-ch-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-ch-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-ch-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-ch-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-ch-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-ch-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-ch-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-ch-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-ch-weekly-2019-11-08--2019-11-15.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/switzerland_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/switzerland_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Switzerland'\n",
    "    df.to_csv('Data/switzerland_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/switzerland_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colombia_masterfile.csv\n",
      "GB_masterfile.csv\n",
      "brazil_masterfile.csv\n",
      "bulgaria_masterfile.csv\n",
      "bolivia_masterfile.csv\n",
      "chile_masterfile.csv\n",
      "belgium_masterfile.csv\n",
      "US_masterfile.csv\n",
      "canada_masterfile.csv\n",
      "switzerland_masterfile.csv\n",
      "argentina_masterfile.csv\n",
      "global_masterfile.csv\n",
      "austria_masterfile.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/all_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    df = pd.read_csv('Data/all_weekly_charts/' + i)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/all_weekly_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_weekly = pd.read_csv('Data/all_weekly_charts/all_weekly_masterfile.csv')\n",
    "\n",
    "# #rename first so they have the same column names to join on\n",
    "left_merged = pd.merge(all_weekly, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\", \"Artist\"])\n",
    "del left_merged['URL']\n",
    "\n",
    "\n",
    "left_merged.to_csv('Data/all_weekly_charts/all_weekly_masterfile_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Streams</th>\n",
       "      <th>Week</th>\n",
       "      <th>Region</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Secreto</td>\n",
       "      <td>Anuel AA</td>\n",
       "      <td>536868</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Con Calma</td>\n",
       "      <td>Daddy Yankee</td>\n",
       "      <td>481026</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Desconocidos</td>\n",
       "      <td>Mau y Ricky</td>\n",
       "      <td>458081</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Adan y Eva</td>\n",
       "      <td>Paulo Londra</td>\n",
       "      <td>455968</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>0.323</td>\n",
       "      <td>0.767</td>\n",
       "      <td>258639.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0676</td>\n",
       "      <td>-4.47</td>\n",
       "      <td>1.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2018-11-05</td>\n",
       "      <td>0.336</td>\n",
       "      <td>171.993</td>\n",
       "      <td>0.72</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Pa Olvidarte (feat. Manuel Turizo) - Remix</td>\n",
       "      <td>ChocQuibTown</td>\n",
       "      <td>455536</td>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148739</th>\n",
       "      <td>196</td>\n",
       "      <td>Little Help</td>\n",
       "      <td>The BossHoss</td>\n",
       "      <td>28802</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148740</th>\n",
       "      <td>197</td>\n",
       "      <td>Ozean</td>\n",
       "      <td>AnnenMayKantereit</td>\n",
       "      <td>28716</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148741</th>\n",
       "      <td>198</td>\n",
       "      <td>Wow.</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>28575</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148742</th>\n",
       "      <td>199</td>\n",
       "      <td>Royal Rumble</td>\n",
       "      <td>Kalazh44</td>\n",
       "      <td>28400</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148743</th>\n",
       "      <td>200</td>\n",
       "      <td>Casanova</td>\n",
       "      <td>Summer Cem</td>\n",
       "      <td>28369</td>\n",
       "      <td>2019-10-11</td>\n",
       "      <td>Austria</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>148744 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Position                                  Track Name  \\\n",
       "0              1                                     Secreto   \n",
       "1              2                                   Con Calma   \n",
       "2              3                                Desconocidos   \n",
       "3              4                                  Adan y Eva   \n",
       "4              5  Pa Olvidarte (feat. Manuel Turizo) - Remix   \n",
       "...          ...                                         ...   \n",
       "148739       196                                 Little Help   \n",
       "148740       197                                       Ozean   \n",
       "148741       198                                        Wow.   \n",
       "148742       199                                Royal Rumble   \n",
       "148743       200                                    Casanova   \n",
       "\n",
       "                   Artist  Streams        Week    Region  acousticness  \\\n",
       "0                Anuel AA   536868  2019-03-01  Colombia           NaN   \n",
       "1            Daddy Yankee   481026  2019-03-01  Colombia           NaN   \n",
       "2             Mau y Ricky   458081  2019-03-01  Colombia           NaN   \n",
       "3            Paulo Londra   455968  2019-03-01  Colombia         0.323   \n",
       "4            ChocQuibTown   455536  2019-03-01  Colombia           NaN   \n",
       "...                   ...      ...         ...       ...           ...   \n",
       "148739       The BossHoss    28802  2019-10-11   Austria           NaN   \n",
       "148740  AnnenMayKantereit    28716  2019-10-11   Austria           NaN   \n",
       "148741        Post Malone    28575  2019-10-11   Austria           NaN   \n",
       "148742           Kalazh44    28400  2019-10-11   Austria           NaN   \n",
       "148743         Summer Cem    28369  2019-10-11   Austria           NaN   \n",
       "\n",
       "        danceability  duration_ms  energy  ...  key liveness  loudness  mode  \\\n",
       "0                NaN          NaN     NaN  ...  NaN      NaN       NaN   NaN   \n",
       "1                NaN          NaN     NaN  ...  NaN      NaN       NaN   NaN   \n",
       "2                NaN          NaN     NaN  ...  NaN      NaN       NaN   NaN   \n",
       "3              0.767     258639.0   0.709  ...  1.0   0.0676     -4.47   1.0   \n",
       "4                NaN          NaN     NaN  ...  NaN      NaN       NaN   NaN   \n",
       "...              ...          ...     ...  ...  ...      ...       ...   ...   \n",
       "148739           NaN          NaN     NaN  ...  NaN      NaN       NaN   NaN   \n",
       "148740           NaN          NaN     NaN  ...  NaN      NaN       NaN   NaN   \n",
       "148741           NaN          NaN     NaN  ...  NaN      NaN       NaN   NaN   \n",
       "148742           NaN          NaN     NaN  ...  NaN      NaN       NaN   NaN   \n",
       "148743           NaN          NaN     NaN  ...  NaN      NaN       NaN   NaN   \n",
       "\n",
       "        popularity  release_date  speechiness    tempo valence    year  \n",
       "0              NaN           NaN          NaN      NaN     NaN     NaN  \n",
       "1              NaN           NaN          NaN      NaN     NaN     NaN  \n",
       "2              NaN           NaN          NaN      NaN     NaN     NaN  \n",
       "3             76.0    2018-11-05        0.336  171.993    0.72  2018.0  \n",
       "4              NaN           NaN          NaN      NaN     NaN     NaN  \n",
       "...            ...           ...          ...      ...     ...     ...  \n",
       "148739         NaN           NaN          NaN      NaN     NaN     NaN  \n",
       "148740         NaN           NaN          NaN      NaN     NaN     NaN  \n",
       "148741         NaN           NaN          NaN      NaN     NaN     NaN  \n",
       "148742         NaN           NaN          NaN      NaN     NaN     NaN  \n",
       "148743         NaN           NaN          NaN      NaN     NaN     NaN  \n",
       "\n",
       "[148744 rows x 23 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "left_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///weekly_charts.sqlite', echo=False)\n",
    "\n",
    "left_merged.to_sql('all_weekly_charts_features', con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
