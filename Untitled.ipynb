{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything required\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spotipy\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite://', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9950</td>\n",
       "      <td>['Carl Woitschach']</td>\n",
       "      <td>0.708</td>\n",
       "      <td>158648</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0</td>\n",
       "      <td>6KbQ3uYMLKb5jDxLF7wYDD</td>\n",
       "      <td>0.563000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-12.428</td>\n",
       "      <td>1</td>\n",
       "      <td>Singende Bataillone 1. Teil</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>118.469</td>\n",
       "      <td>0.7790</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9940</td>\n",
       "      <td>['Robert Schumann', 'Vladimir Horowitz']</td>\n",
       "      <td>0.379</td>\n",
       "      <td>282133</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0</td>\n",
       "      <td>6KuQTIu1KoTTkLXKrwlLPV</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>-28.454</td>\n",
       "      <td>1</td>\n",
       "      <td>Fantasiestücke, Op. 111: Più tosto lento</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>83.972</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6040</td>\n",
       "      <td>['Seweryn Goszczyński']</td>\n",
       "      <td>0.749</td>\n",
       "      <td>104300</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0</td>\n",
       "      <td>6L63VW0PibdM1HDSBoqnoM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-19.924</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter 1.18 - Zamek kaniowski</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>107.177</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9950</td>\n",
       "      <td>['Francisco Canaro']</td>\n",
       "      <td>0.781</td>\n",
       "      <td>180760</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0</td>\n",
       "      <td>6M94FkXd15sOAOQYRnWPN8</td>\n",
       "      <td>0.887000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-14.734</td>\n",
       "      <td>0</td>\n",
       "      <td>Bebamos Juntos - Instrumental (Remasterizado)</td>\n",
       "      <td>0</td>\n",
       "      <td>1928-09-25</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>108.003</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9900</td>\n",
       "      <td>['Frédéric Chopin', 'Vladimir Horowitz']</td>\n",
       "      <td>0.210</td>\n",
       "      <td>687733</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0</td>\n",
       "      <td>6N6tiFZ9vLTSOIxkj8qKrd</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>-16.829</td>\n",
       "      <td>1</td>\n",
       "      <td>Polonaise-Fantaisie in A-Flat Major, Op. 61</td>\n",
       "      <td>1</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>62.149</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169904</th>\n",
       "      <td>0.1730</td>\n",
       "      <td>['DripReport', 'Tyga']</td>\n",
       "      <td>0.875</td>\n",
       "      <td>163800</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>1</td>\n",
       "      <td>4KppkflX7I3vJQk7urOJaS</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>-7.461</td>\n",
       "      <td>1</td>\n",
       "      <td>Skechers (feat. Tyga) - Remix</td>\n",
       "      <td>75</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>100.012</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169905</th>\n",
       "      <td>0.0167</td>\n",
       "      <td>['Leon Bridges', 'Terrace Martin']</td>\n",
       "      <td>0.719</td>\n",
       "      <td>167468</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0</td>\n",
       "      <td>1ehhGlTvjtHo2e4xJFB0SZ</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-10.907</td>\n",
       "      <td>1</td>\n",
       "      <td>Sweeter (feat. Terrace Martin)</td>\n",
       "      <td>64</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>128.000</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169906</th>\n",
       "      <td>0.5380</td>\n",
       "      <td>['Kygo', 'Oh Wonder']</td>\n",
       "      <td>0.514</td>\n",
       "      <td>180700</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0</td>\n",
       "      <td>52eycxprLhK3lPcRLbQiVk</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>-9.332</td>\n",
       "      <td>1</td>\n",
       "      <td>How Would I Know</td>\n",
       "      <td>70</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>123.700</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169907</th>\n",
       "      <td>0.0714</td>\n",
       "      <td>['Cash Cash', 'Andy Grammer']</td>\n",
       "      <td>0.646</td>\n",
       "      <td>167308</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0</td>\n",
       "      <td>3wYOGJYD31sLRmBgCvWxa4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>-2.557</td>\n",
       "      <td>1</td>\n",
       "      <td>I Found You</td>\n",
       "      <td>70</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>129.916</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169908</th>\n",
       "      <td>0.1090</td>\n",
       "      <td>['Ingrid Andress']</td>\n",
       "      <td>0.512</td>\n",
       "      <td>214787</td>\n",
       "      <td>0.4280</td>\n",
       "      <td>0</td>\n",
       "      <td>60RFlt48hm0l4Fu0JoccOl</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>-7.387</td>\n",
       "      <td>1</td>\n",
       "      <td>More Hearts Than Mine</td>\n",
       "      <td>65</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>80.588</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169909 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acousticness                                   artists  danceability  \\\n",
       "0             0.9950                       ['Carl Woitschach']         0.708   \n",
       "1             0.9940  ['Robert Schumann', 'Vladimir Horowitz']         0.379   \n",
       "2             0.6040                   ['Seweryn Goszczyński']         0.749   \n",
       "3             0.9950                      ['Francisco Canaro']         0.781   \n",
       "4             0.9900  ['Frédéric Chopin', 'Vladimir Horowitz']         0.210   \n",
       "...              ...                                       ...           ...   \n",
       "169904        0.1730                    ['DripReport', 'Tyga']         0.875   \n",
       "169905        0.0167        ['Leon Bridges', 'Terrace Martin']         0.719   \n",
       "169906        0.5380                     ['Kygo', 'Oh Wonder']         0.514   \n",
       "169907        0.0714             ['Cash Cash', 'Andy Grammer']         0.646   \n",
       "169908        0.1090                        ['Ingrid Andress']         0.512   \n",
       "\n",
       "        duration_ms  energy  explicit                      id  \\\n",
       "0            158648  0.1950         0  6KbQ3uYMLKb5jDxLF7wYDD   \n",
       "1            282133  0.0135         0  6KuQTIu1KoTTkLXKrwlLPV   \n",
       "2            104300  0.2200         0  6L63VW0PibdM1HDSBoqnoM   \n",
       "3            180760  0.1300         0  6M94FkXd15sOAOQYRnWPN8   \n",
       "4            687733  0.2040         0  6N6tiFZ9vLTSOIxkj8qKrd   \n",
       "...             ...     ...       ...                     ...   \n",
       "169904       163800  0.4430         1  4KppkflX7I3vJQk7urOJaS   \n",
       "169905       167468  0.3850         0  1ehhGlTvjtHo2e4xJFB0SZ   \n",
       "169906       180700  0.5390         0  52eycxprLhK3lPcRLbQiVk   \n",
       "169907       167308  0.7610         0  3wYOGJYD31sLRmBgCvWxa4   \n",
       "169908       214787  0.4280         0  60RFlt48hm0l4Fu0JoccOl   \n",
       "\n",
       "        instrumentalness  key  liveness  loudness  mode  \\\n",
       "0               0.563000   10    0.1510   -12.428     1   \n",
       "1               0.901000    8    0.0763   -28.454     1   \n",
       "2               0.000000    5    0.1190   -19.924     0   \n",
       "3               0.887000    1    0.1110   -14.734     0   \n",
       "4               0.908000   11    0.0980   -16.829     1   \n",
       "...                  ...  ...       ...       ...   ...   \n",
       "169904          0.000032    1    0.0891    -7.461     1   \n",
       "169905          0.031300    8    0.1110   -10.907     1   \n",
       "169906          0.002330    7    0.1080    -9.332     1   \n",
       "169907          0.000000    1    0.2220    -2.557     1   \n",
       "169908          0.000000    0    0.1050    -7.387     1   \n",
       "\n",
       "                                           Track Name  popularity  \\\n",
       "0                         Singende Bataillone 1. Teil           0   \n",
       "1            Fantasiestücke, Op. 111: Più tosto lento           0   \n",
       "2                      Chapter 1.18 - Zamek kaniowski           0   \n",
       "3       Bebamos Juntos - Instrumental (Remasterizado)           0   \n",
       "4         Polonaise-Fantaisie in A-Flat Major, Op. 61           1   \n",
       "...                                               ...         ...   \n",
       "169904                  Skechers (feat. Tyga) - Remix          75   \n",
       "169905                 Sweeter (feat. Terrace Martin)          64   \n",
       "169906                               How Would I Know          70   \n",
       "169907                                    I Found You          70   \n",
       "169908                          More Hearts Than Mine          65   \n",
       "\n",
       "       release_date  speechiness    tempo  valence  year  \n",
       "0              1928       0.0506  118.469   0.7790  1928  \n",
       "1              1928       0.0462   83.972   0.0767  1928  \n",
       "2              1928       0.9290  107.177   0.8800  1928  \n",
       "3        1928-09-25       0.0926  108.003   0.7200  1928  \n",
       "4              1928       0.0424   62.149   0.0693  1928  \n",
       "...             ...          ...      ...      ...   ...  \n",
       "169904   2020-05-15       0.1430  100.012   0.3060  2020  \n",
       "169905   2020-06-08       0.0403  128.000   0.2700  2020  \n",
       "169906   2020-05-29       0.1050  123.700   0.1530  2020  \n",
       "169907   2020-02-28       0.0385  129.916   0.4720  2020  \n",
       "169908   2020-03-27       0.0271   80.588   0.3660  2020  \n",
       "\n",
       "[169909 rows x 19 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_features = pd.read_csv(r'all_songs_data/data.csv')\n",
    "\n",
    "track_features = track_features.rename(columns={\"name\" : \"Track Name\"})\n",
    "\n",
    "#track_features.replace(to_replace= '[]', value = '')\n",
    "                                                \n",
    "track_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_chart0104 = pd.read_csv(r'global weekly charts/regional-global-weekly-2018-12-28--2019-01-04.csv')\n",
    "\n",
    "global_0104_df = pd.DataFrame(global_chart0104)\n",
    "\n",
    "# Column Reordering\n",
    "global_0104_df = global_0104_df.rename(columns={\"Unnamed: 0\" : \"Position\",\n",
    "                                      \"Unnamed: 1\" : \"Track Name\",\n",
    "                                      \"Unnamed: 2\" : \"Artist\",\n",
    "                                      \"Note that these figures are generated using a formula that protects against any artificial inflation of chart positions.\": \"Streams\",\n",
    "                                         \"Unnamed: 4\" : \"URL\",})\n",
    "global_0104 = global_0104_df.drop([0])\n",
    "\n",
    "global_0104.reset_index\n",
    "\n",
    "global_0104['Week'] = ''\n",
    "\n",
    "global_0104['Week'] = global_0104['Week'].replace([''],'01-04')\n",
    "\n",
    "global_0104\n",
    "\n",
    "GlobalFeatures_0104 = pd.merge(global_0104, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\"])\n",
    "GlobalFeatures_0104\n",
    "\n",
    "#create csv from merged data\n",
    "GlobalFeatures_0104.to_csv(r'global_merged_weekly_charts/GlobalFeatures_0104.csv')\n",
    "\n",
    "#push up to sqlite\n",
    "GlobalFeatures_0104.to_sql('GlobalFeatures_0104', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_chart0111 = pd.read_csv(r'global weekly charts/regional-global-weekly-2019-01-04--2019-01-11.csv')\n",
    "\n",
    "global_0111_df = pd.DataFrame(global_chart0111)\n",
    "\n",
    "# Column Reordering\n",
    "global_0111_df = global_0111_df.rename(columns={\"Unnamed: 0\" : \"Position\",\n",
    "                                      \"Unnamed: 1\" : \"Track Name\",\n",
    "                                      \"Unnamed: 2\" : \"Artist\",\n",
    "                                      \"Note that these figures are generated using a formula that protects against any artificial inflation of chart positions.\": \"Streams\",\n",
    "                                         \"Unnamed: 4\" : \"URL\",})\n",
    "global_0111 = global_0111_df.drop([0])\n",
    "\n",
    "global_0111.reset_index\n",
    "\n",
    "global_0111['Week'] = ''\n",
    "\n",
    "global_0111['Week'] = global_0111['Week'].replace([''],'01-11')\n",
    "\n",
    "global_0111\n",
    "\n",
    "GlobalFeatures_0111 = pd.merge(global_0111, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\"])\n",
    "GlobalFeatures_0111\n",
    "\n",
    "#create csv from merged data\n",
    "GlobalFeatures_0111.to_csv(r'global_merged_weekly_charts/GlobalFeatures_0111.csv')\n",
    "\n",
    "#push up to sqlite\n",
    "GlobalFeatures_0111.to_sql('GlobalFeatures_0111', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_chart0118 = pd.read_csv(r'global weekly charts/regional-global-weekly-2019-01-11--2019-01-18.csv')\n",
    "\n",
    "global_0118_df = pd.DataFrame(global_chart0118)\n",
    "\n",
    "# Column Reordering\n",
    "global_0118_df = global_0118_df.rename(columns={\"Unnamed: 0\" : \"Position\",\n",
    "                                      \"Unnamed: 1\" : \"Track Name\",\n",
    "                                      \"Unnamed: 2\" : \"Artist\",\n",
    "                                      \"Note that these figures are generated using a formula that protects against any artificial inflation of chart positions.\": \"Streams\",\n",
    "                                         \"Unnamed: 4\" : \"URL\",})\n",
    "global_0118 = global_0118_df.drop([0])\n",
    "\n",
    "global_0118.reset_index\n",
    "\n",
    "global_0118['Week'] = ''\n",
    "\n",
    "global_0118['Week'] = global_0118['Week'].replace([''],'01-18')\n",
    "\n",
    "global_0118\n",
    "\n",
    "GlobalFeatures_0118 = pd.merge(global_0118, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\"])\n",
    "GlobalFeatures_0118\n",
    "\n",
    "#create csv from merged data\n",
    "GlobalFeatures_0118.to_csv(r'global_merged_weekly_charts/GlobalFeatures_0118.csv')\n",
    "\n",
    "#push up to sqlite\n",
    "GlobalFeatures_0118.to_sql('GlobalFeatures_0118', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_chart0125 = pd.read_csv(r'global weekly charts/regional-global-weekly-2019-01-18--2019-01-25.csv')\n",
    "\n",
    "global_0125_df = pd.DataFrame(global_chart0125)\n",
    "\n",
    "# Column Reordering\n",
    "global_0125_df = global_0125_df.rename(columns={\"Unnamed: 0\" : \"Position\",\n",
    "                                      \"Unnamed: 1\" : \"Track Name\",\n",
    "                                      \"Unnamed: 2\" : \"Artist\",\n",
    "                                      \"Note that these figures are generated using a formula that protects against any artificial inflation of chart positions.\": \"Streams\",\n",
    "                                         \"Unnamed: 4\" : \"URL\",})\n",
    "global_0125 = global_0125_df.drop([0])\n",
    "\n",
    "global_0125.reset_index\n",
    "\n",
    "global_0125['Week'] = ''\n",
    "\n",
    "global_0125['Week'] = global_0125['Week'].replace([''],'01-25')\n",
    "\n",
    "global_0125\n",
    "\n",
    "GlobalFeatures_0125 = pd.merge(global_0125, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\"])\n",
    "GlobalFeatures_0125\n",
    "\n",
    "#create csv from merged data\n",
    "GlobalFeatures_0125.to_csv(r'global_merged_weekly_charts/GlobalFeatures_0125.csv')\n",
    "\n",
    "#push up to sqlite\n",
    "GlobalFeatures_0125.to_sql('GlobalFeatures_0125', con=engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Streams</th>\n",
       "      <th>URL</th>\n",
       "      <th>Week</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>artists</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>...</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7 rings</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>71467874</td>\n",
       "      <td>https://open.spotify.com/track/14msK75pk3pA33p...</td>\n",
       "      <td>01-25</td>\n",
       "      <td>0.59200</td>\n",
       "      <td>['Ariana Grande']</td>\n",
       "      <td>0.778</td>\n",
       "      <td>178627.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>-10.732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>140.048</td>\n",
       "      <td>0.327</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Sunflower - Spider-Man: Into the Spider-Verse</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>33799389</td>\n",
       "      <td>https://open.spotify.com/track/3KkXRkHbMCARz0a...</td>\n",
       "      <td>01-25</td>\n",
       "      <td>0.55600</td>\n",
       "      <td>['Post Malone', 'Swae Lee']</td>\n",
       "      <td>0.760</td>\n",
       "      <td>158040.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>-5.574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2018-12-14</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>89.911</td>\n",
       "      <td>0.913</td>\n",
       "      <td>2018.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Wow.</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>31165644</td>\n",
       "      <td>https://open.spotify.com/track/6MWtB6iiXyIwun0...</td>\n",
       "      <td>01-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>thank u, next</td>\n",
       "      <td>Ariana Grande</td>\n",
       "      <td>27672341</td>\n",
       "      <td>https://open.spotify.com/track/2rPE9A1vEgShuZx...</td>\n",
       "      <td>01-25</td>\n",
       "      <td>0.22900</td>\n",
       "      <td>['Ariana Grande']</td>\n",
       "      <td>0.717</td>\n",
       "      <td>207320.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>-5.634</td>\n",
       "      <td>1.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2019-02-08</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>106.966</td>\n",
       "      <td>0.412</td>\n",
       "      <td>2019.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Without Me</td>\n",
       "      <td>Halsey</td>\n",
       "      <td>27576694</td>\n",
       "      <td>https://open.spotify.com/track/5p7ujcrUXASCNwR...</td>\n",
       "      <td>01-25</td>\n",
       "      <td>0.00317</td>\n",
       "      <td>['Eminem']</td>\n",
       "      <td>0.924</td>\n",
       "      <td>290120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.1930</td>\n",
       "      <td>-3.349</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>2002-05-26</td>\n",
       "      <td>0.0712</td>\n",
       "      <td>112.239</td>\n",
       "      <td>0.678</td>\n",
       "      <td>2002.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Position                                     Track Name         Artist  \\\n",
       "0        1                                        7 rings  Ariana Grande   \n",
       "1        2  Sunflower - Spider-Man: Into the Spider-Verse    Post Malone   \n",
       "2        3                                           Wow.    Post Malone   \n",
       "3        4                                  thank u, next  Ariana Grande   \n",
       "4        5                                     Without Me         Halsey   \n",
       "\n",
       "    Streams                                                URL   Week  \\\n",
       "0  71467874  https://open.spotify.com/track/14msK75pk3pA33p...  01-25   \n",
       "1  33799389  https://open.spotify.com/track/3KkXRkHbMCARz0a...  01-25   \n",
       "2  31165644  https://open.spotify.com/track/6MWtB6iiXyIwun0...  01-25   \n",
       "3  27672341  https://open.spotify.com/track/2rPE9A1vEgShuZx...  01-25   \n",
       "4  27576694  https://open.spotify.com/track/5p7ujcrUXASCNwR...  01-25   \n",
       "\n",
       "   acousticness                      artists  danceability  duration_ms  ...  \\\n",
       "0       0.59200            ['Ariana Grande']         0.778     178627.0  ...   \n",
       "1       0.55600  ['Post Malone', 'Swae Lee']         0.760     158040.0  ...   \n",
       "2           NaN                          NaN           NaN          NaN  ...   \n",
       "3       0.22900            ['Ariana Grande']         0.717     207320.0  ...   \n",
       "4       0.00317                   ['Eminem']         0.924     290120.0  ...   \n",
       "\n",
       "   key  liveness loudness  mode  popularity  release_date  speechiness  \\\n",
       "0  1.0    0.0881  -10.732   0.0        87.0    2019-02-08       0.3340   \n",
       "1  2.0    0.0703   -5.574   1.0        86.0    2018-12-14       0.0466   \n",
       "2  NaN       NaN      NaN   NaN         NaN           NaN          NaN   \n",
       "3  1.0    0.1010   -5.634   1.0        85.0    2019-02-08       0.0658   \n",
       "4  7.0    0.1930   -3.349   1.0        38.0    2002-05-26       0.0712   \n",
       "\n",
       "     tempo  valence    year  \n",
       "0  140.048    0.327  2019.0  \n",
       "1   89.911    0.913  2018.0  \n",
       "2      NaN      NaN     NaN  \n",
       "3  106.966    0.412  2019.0  \n",
       "4  112.239    0.678  2002.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GlobalFeatures_0125.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_chart0201 = pd.read_csv(r'global weekly charts/regional-global-weekly-2019-01-25--2019-02-01.csv')\n",
    "\n",
    "global_0201_df = pd.DataFrame(global_chart0201)\n",
    "\n",
    "# Column Reordering\n",
    "global_0201_df = global_0201_df.rename(columns={\"Unnamed: 0\" : \"Position\",\n",
    "                                      \"Unnamed: 1\" : \"Track Name\",\n",
    "                                      \"Unnamed: 2\" : \"Artist\",\n",
    "                                      \"Note that these figures are generated using a formula that protects against any artificial inflation of chart positions.\": \"Streams\",\n",
    "                                         \"Unnamed: 4\" : \"URL\",})\n",
    "global_0201 = global_0201_df.drop([0])\n",
    "\n",
    "global_0201.reset_index\n",
    "\n",
    "global_0201['Week'] = ''\n",
    "\n",
    "global_0201['Week'] = global_0201['Week'].replace([''],'02-01')\n",
    "\n",
    "global_0201\n",
    "\n",
    "GlobalFeatures_0201 = pd.merge(global_0201, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\"])\n",
    "GlobalFeatures_0201\n",
    "\n",
    "#create csv from merged data\n",
    "GlobalFeatures_0201.to_csv(r'global_merged_weekly_charts/GlobalFeatures_0201.csv')\n",
    "\n",
    "#push up to sqlite\n",
    "GlobalFeatures_0201.to_sql('GlobalFeatures_0201', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Table 'GlobalFeatures_0215' already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-1771e56d3d43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m#push up to sqlite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mGlobalFeatures_0215\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'GlobalFeatures_0215'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   2661\u001b[0m             \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2662\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2663\u001b[0;31m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2664\u001b[0m         )\n\u001b[1;32m   2665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m         \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     )\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[0;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m         )\n\u001b[0;32m-> 1316\u001b[0;31m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m         \u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdigit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    644\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"fail\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Table '{self.name}' already exists.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Table 'GlobalFeatures_0215' already exists."
     ]
    }
   ],
   "source": [
    "global_chart0215 = pd.read_csv(r'global weekly charts/regional-global-weekly-2019-02-08--2019-02-15.csv')\n",
    "\n",
    "global_0215_df = pd.DataFrame(global_chart0125)\n",
    "\n",
    "# Column Reordering\n",
    "global_0215_df = global_0215_df.rename(columns={\"Unnamed: 0\" : \"Position\",\n",
    "                                      \"Unnamed: 1\" : \"Track Name\",\n",
    "                                      \"Unnamed: 2\" : \"Artist\",\n",
    "                                      \"Note that these figures are generated using a formula that protects against any artificial inflation of chart positions.\": \"Streams\",\n",
    "                                         \"Unnamed: 4\" : \"URL\",})\n",
    "global_0215 = global_0215_df.drop([0])\n",
    "\n",
    "global_0215.reset_index\n",
    "\n",
    "global_0215['Week'] = ''\n",
    "\n",
    "global_0215['Week'] = global_0215['Week'].replace([''],'02-15')\n",
    "\n",
    "global_0215\n",
    "\n",
    "GlobalFeatures_0215 = pd.merge(global_0215, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\"])\n",
    "GlobalFeatures_0215\n",
    "\n",
    "#create csv from merged data\n",
    "GlobalFeatures_0215.to_csv(r'global_merged_weekly_charts/GlobalFeatures_0215.csv')\n",
    "\n",
    "#push up to sqlite\n",
    "GlobalFeatures_0215.to_sql('GlobalFeatures_0215', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_chart0222 = pd.read_csv(r'global weekly charts/regional-global-weekly-2019-02-15--2019-02-22.csv')\n",
    "\n",
    "global_0222_df = pd.DataFrame(global_chart0222)\n",
    "\n",
    "# Column Reordering\n",
    "global_0222_df = global_0222_df.rename(columns={\"Unnamed: 0\" : \"Position\",\n",
    "                                      \"Unnamed: 1\" : \"Track Name\",\n",
    "                                      \"Unnamed: 2\" : \"Artist\",\n",
    "                                      \"Note that these figures are generated using a formula that protects against any artificial inflation of chart positions.\": \"Streams\",\n",
    "                                         \"Unnamed: 4\" : \"URL\",})\n",
    "global_0222 = global_0222_df.drop([0])\n",
    "\n",
    "global_0222.reset_index\n",
    "\n",
    "global_0222['Week'] = ''\n",
    "\n",
    "global_0222['Week'] = global_0222['Week'].replace([''],'02-22')\n",
    "\n",
    "global_0222\n",
    "\n",
    "GlobalFeatures_0222 = pd.merge(global_0222, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\"])\n",
    "GlobalFeatures_0222\n",
    "\n",
    "#create csv from merged data\n",
    "GlobalFeatures_0222.to_csv(r'global_merged_weekly_charts/GlobalFeatures_0222.csv')\n",
    "\n",
    "#push up to sqlite\n",
    "GlobalFeatures_0222.to_sql('GlobalFeatures_0222', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_chart0301 = pd.read_csv(r'global weekly charts/regional-global-weekly-2019-02-22--2019-03-01.csv')\n",
    "\n",
    "global_00301_df = pd.DataFrame(global_chart0301)\n",
    "\n",
    "# Column Reordering\n",
    "global_0301_df = global_0301_df.rename(columns={\"Unnamed: 0\" : \"Position\",\n",
    "                                      \"Unnamed: 1\" : \"Track Name\",\n",
    "                                      \"Unnamed: 2\" : \"Artist\",\n",
    "                                      \"Note that these figures are generated using a formula that protects against any artificial inflation of chart positions.\": \"Streams\",\n",
    "                                         \"Unnamed: 4\" : \"URL\",})\n",
    "global_0301 = global_0301_df.drop([0])\n",
    "\n",
    "global_0301.reset_index\n",
    "\n",
    "global_0301['Week'] = ''\n",
    "\n",
    "global_0301['Week'] = global_0301['Week'].replace([''],'03-01')\n",
    "\n",
    "global_0301\n",
    "\n",
    "GlobalFeatures_0301 = pd.merge(global_0301, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\"])\n",
    "GlobalFeatures_0301\n",
    "\n",
    "#create csv from merged data\n",
    "GlobalFeatures_0301.to_csv(r'global_merged_weekly_charts/GlobalFeatures_0301.csv')\n",
    "\n",
    "#push up to sqlite\n",
    "GlobalFeatures_0301.to_sql('GlobalFeatures_0301', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_chart0308 = pd.read_csv(r'global weekly charts/regional-global-weekly-2019-03-01--2019-03-08.csv')\n",
    "\n",
    "global_0308_df = pd.DataFrame(global_chart0308)\n",
    "\n",
    "# Column Reordering\n",
    "global_0308_df = global_0308_df.rename(columns={\"Unnamed: 0\" : \"Position\",\n",
    "                                      \"Unnamed: 1\" : \"Track Name\",\n",
    "                                      \"Unnamed: 2\" : \"Artist\",\n",
    "                                      \"Note that these figures are generated using a formula that protects against any artificial inflation of chart positions.\": \"Streams\",\n",
    "                                         \"Unnamed: 4\" : \"URL\",})\n",
    "global_0308 = global_0308_df.drop([0])\n",
    "\n",
    "global_0308.reset_index\n",
    "\n",
    "global_0308['Week'] = ''\n",
    "\n",
    "global_0308['Week'] = global_0308['Week'].replace([''],'03-08')\n",
    "\n",
    "global_0308\n",
    "\n",
    "GlobalFeatures_0308 = pd.merge(global_0308, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\"])\n",
    "GlobalFeatures_0308\n",
    "\n",
    "#create csv from merged data\n",
    "GlobalFeatures_0308.to_csv(r'global_merged_weekly_charts/GlobalFeatures_0308.csv')\n",
    "\n",
    "#push up to sqlite\n",
    "GlobalFeatures_0308.to_sql('GlobalFeatures_0308', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_chart0315 = pd.read_csv(r'global weekly charts/regional-global-weekly-2019-03-08--2019-03-15.csv')\n",
    "\n",
    "global_0315_df = pd.DataFrame(global_chart0315)\n",
    "\n",
    "# Column Reordering\n",
    "global_0315_df = global_0315_df.rename(columns={\"Unnamed: 0\" : \"Position\",\n",
    "                                      \"Unnamed: 1\" : \"Track Name\",\n",
    "                                      \"Unnamed: 2\" : \"Artist\",\n",
    "                                      \"Note that these figures are generated using a formula that protects against any artificial inflation of chart positions.\": \"Streams\",\n",
    "                                         \"Unnamed: 4\" : \"URL\",})\n",
    "global_0315 = global_0315_df.drop([0])\n",
    "\n",
    "global_0315.reset_index\n",
    "\n",
    "global_0315['Week'] = ''\n",
    "\n",
    "global_0315['Week'] = global_0315['Week'].replace([''],'03-15')\n",
    "\n",
    "global_0315\n",
    "\n",
    "GlobalFeatures_0315 = pd.merge(global_0315, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\"])\n",
    "GlobalFeatures_0315\n",
    "\n",
    "#create csv from merged data\n",
    "GlobalFeatures_0315.to_csv(r'global_merged_weekly_charts/GlobalFeatures_0315.csv')\n",
    "\n",
    "#push up to sqlite\n",
    "GlobalFeatures_0315.to_sql('GlobalFeatures_0315', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_chart0322 = pd.read_csv(r'global weekly charts/regional-global-weekly-2019-03-15--2019-03-22.csv')\n",
    "\n",
    "global_0322_df = pd.DataFrame(global_chart0322)\n",
    "\n",
    "# Column Reordering\n",
    "global_0322_df = global_0322_df.rename(columns={\"Unnamed: 0\" : \"Position\",\n",
    "                                      \"Unnamed: 1\" : \"Track Name\",\n",
    "                                      \"Unnamed: 2\" : \"Artist\",\n",
    "                                      \"Note that these figures are generated using a formula that protects against any artificial inflation of chart positions.\": \"Streams\",\n",
    "                                         \"Unnamed: 4\" : \"URL\",})\n",
    "global_0322 = global_0322_df.drop([0])\n",
    "\n",
    "global_0322.reset_index\n",
    "\n",
    "global_0322['Week'] = ''\n",
    "\n",
    "global_0322['Week'] = global_0322['Week'].replace([''],'03-22')\n",
    "\n",
    "global_0322\n",
    "\n",
    "GlobalFeatures_0322 = pd.merge(global_0322, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\"])\n",
    "GlobalFeatures_0322\n",
    "\n",
    "#create csv from merged data\n",
    "GlobalFeatures_0322.to_csv(r'global_merged_weekly_charts/GlobalFeatures_0322.csv')\n",
    "\n",
    "#push up to sqlite\n",
    "GlobalFeatures_0322.to_sql('GlobalFeatures_0322', con=engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
