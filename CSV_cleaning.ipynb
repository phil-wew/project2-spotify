{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "import os\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "#launch engine for sqlite\n",
    "engine = create_engine('sqlite://', echo=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv with track features, edit colum names to match other csvs, and fix the artist names by removing unnecessary symmbols.\n",
    "track_features = pd.read_csv(r'Data/all_songs_data/data.csv')\n",
    "\n",
    "track_features = track_features.rename(columns={\"name\" : \"Track Name\", \"artists\" : \"Artist\"})\n",
    "\n",
    "track_features.loc[:,'Artist'] = track_features.Artist.map(lambda x: x.replace(\"['\", \"\").replace(\"']\",\"\"))\n",
    "                                                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through folder with regional weekly charts\n",
    "filenames = [i for i in os.listdir('Data/global_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "#take the week's date from csv name and insert it in \"date\" column of csv.\n",
    "for i in filenames:\n",
    "    date = i[35:45]\n",
    "    df = pd.read_csv('Data/global_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Global'\n",
    "    df.to_csv('Data/global_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #concat csv to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    \n",
    "    #print(df.columns)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/global_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "filenames = [i for i in os.listdir('Data/argentina_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/argentina_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Argentina'\n",
    "    df.to_csv('Data/argentina_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/argentina_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "filenames = [i for i in os.listdir('Data/austria_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/austria_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Austria'\n",
    "    df.to_csv('Data/austria_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/austria_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "filenames = [i for i in os.listdir('Data/belgium_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/belgium_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Belgium'\n",
    "    df.to_csv('Data/belgium_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/belgium_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "filenames = [i for i in os.listdir('Data/bolivia_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/bolivia_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Bolivia'\n",
    "    df.to_csv('Data/bolivia_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/bolivia_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "filenames = [i for i in os.listdir('Data/brazil_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/brazil_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Brazil'\n",
    "    df.to_csv('Data/brazil_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/brazil_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "filenames = [i for i in os.listdir('Data/canada_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/canada_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Canada'\n",
    "    df.to_csv('Data/canada_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/canada_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "filenames = [i for i in os.listdir('Data/chile_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/chile_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Chile'\n",
    "    df.to_csv('Data/chile_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/chile_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "filenames = [i for i in os.listdir('Data/colombia_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/colombia_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Colombia'\n",
    "    df.to_csv('Data/colombia_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/colombia_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "# filenames = [i for i in os.listdir('Data/france_weekly_charts') if \".csv\" in i]\n",
    "# alldata = pd.DataFrame()\n",
    "\n",
    "# for i in filenames:\n",
    "#     date = i[31:41]\n",
    "#     df = pd.read_csv('Data/france_weekly_charts/' + i, header = 1)\n",
    "#     df.loc[:,'Week']= date\n",
    "#     df.loc[:,'Region'] = 'France'\n",
    "#     df.to_csv('Data/france_weekly_charts/' + i, index = False)\n",
    "    \n",
    "#     #Now accumulate to master file\n",
    "#     alldata = pd.concat((alldata, df))\n",
    "#     print(i)\n",
    "\n",
    "# alldata.to_csv('Data/all_weekly_charts/france_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#repeat loop for next region's weekly chartsfilenames = [i for i in os.listdir('Data/GB_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/GB_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Great Britain'\n",
    "    df.to_csv('Data/GB_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/GB_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "filenames = [i for i in os.listdir('Data/US_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/US_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'United States of America'\n",
    "    df.to_csv('Data/US_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/US_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "filenames = [i for i in os.listdir('Data/bulgaria_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/bulgaria_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Bulgaria'\n",
    "    df.to_csv('Data/bulgaria_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/bulgaria_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repeat loop for next region's weekly charts\n",
    "filenames = [i for i in os.listdir('Data/switzerland_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/switzerland_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Switzerland'\n",
    "    df.to_csv('Data/switzerland_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/switzerland_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop through all regional csvs in folder\n",
    "filenames = [i for i in os.listdir('Data/all_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in filenames:\n",
    "    df = pd.read_csv('Data/all_weekly_charts/' + i)\n",
    "    \n",
    "    #combine all regional csvs to a master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    #print(i)\n",
    "#save the csv\n",
    "alldata.to_csv('Data/all_weekly_charts/all_weekly_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_weekly = pd.read_csv('Data/all_weekly_charts/all_weekly_masterfile.csv')\n",
    "\n",
    "# #rename column to have the same column names to join on\n",
    "left_merged = pd.merge(all_weekly, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\", \"Artist\"])\n",
    "#drop unneeded column\n",
    "del left_merged['URL']\n",
    "\n",
    "# Group data by region \n",
    "region_groups = left_merged.groupby('Region').agg({\n",
    "    'Streams' : 'sum',\n",
    "    'Track Name' : 'sum',\n",
    "    'Artist' : 'sum',\n",
    "    'acousticness' : 'mean',\n",
    "    'danceability' : 'mean',\n",
    "    'duration_ms' : 'mean',\n",
    "    'energy' : 'mean',\n",
    "    'key' : 'value_counts',\n",
    "    'liveness' : 'mean',\n",
    "    'instrumentalness' : 'mean',\n",
    "    'loudness' : 'mean',\n",
    "    'mode' : 'mean',\n",
    "    'popularity' : 'mean',\n",
    "    'danceability' : 'mean',\n",
    "    'energy' : 'mean',\n",
    "    'mode' : 'mean',\n",
    "    'valence' : 'mean',\n",
    "    'tempo' : 'mean',\n",
    "    'speechiness' : 'mean',\n",
    "    'danceability' : 'mean',\n",
    "    \n",
    "})\n",
    "\n",
    "\n",
    "#left_merged.to_csv('Data/all_weekly_charts/all_weekly_masterfile_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTF-8\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>top genre</th>\n",
       "      <th>year</th>\n",
       "      <th>added</th>\n",
       "      <th>bpm</th>\n",
       "      <th>nrgy</th>\n",
       "      <th>dnce</th>\n",
       "      <th>dB</th>\n",
       "      <th>live</th>\n",
       "      <th>val</th>\n",
       "      <th>dur</th>\n",
       "      <th>acous</th>\n",
       "      <th>spch</th>\n",
       "      <th>pop</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dance Monkey</td>\n",
       "      <td>Tones and I</td>\n",
       "      <td>australian pop</td>\n",
       "      <td>2019</td>\n",
       "      <td>1969-12-31</td>\n",
       "      <td>98.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>209</td>\n",
       "      <td>69.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>100</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>ROXANNE</td>\n",
       "      <td>Arizona Zervas</td>\n",
       "      <td>pop rap</td>\n",
       "      <td>2019</td>\n",
       "      <td>1969-12-31</td>\n",
       "      <td>117.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>164</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>99</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Memories</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>pop</td>\n",
       "      <td>2019</td>\n",
       "      <td>1969-12-31</td>\n",
       "      <td>91.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>189</td>\n",
       "      <td>84.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>99</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Circles</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>dfw rap</td>\n",
       "      <td>2019</td>\n",
       "      <td>1969-12-31</td>\n",
       "      <td>120.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>215</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>99</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>All I Want for Christmas Is You</td>\n",
       "      <td>Mariah Carey</td>\n",
       "      <td>dance pop</td>\n",
       "      <td>1994</td>\n",
       "      <td>1969-12-31</td>\n",
       "      <td>150.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>241</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>98</td>\n",
       "      <td>world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>Feelings</td>\n",
       "      <td>Lauv</td>\n",
       "      <td>pop</td>\n",
       "      <td>2019</td>\n",
       "      <td>1969-12-31</td>\n",
       "      <td>103.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>190</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>73</td>\n",
       "      <td>malasya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>Mimpi (feat. Alif)</td>\n",
       "      <td>K-Clique</td>\n",
       "      <td>malaysian indie</td>\n",
       "      <td>2019</td>\n",
       "      <td>1969-12-31</td>\n",
       "      <td>150.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>253</td>\n",
       "      <td>53.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>66</td>\n",
       "      <td>malasya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>Cinta Luar Biasa</td>\n",
       "      <td>Andmesh</td>\n",
       "      <td>indonesian pop</td>\n",
       "      <td>2019</td>\n",
       "      <td>1969-12-31</td>\n",
       "      <td>136.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>256</td>\n",
       "      <td>81.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>66</td>\n",
       "      <td>malasya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>Haa Tepok</td>\n",
       "      <td>MeerFly</td>\n",
       "      <td>malaysian hip hop</td>\n",
       "      <td>2019</td>\n",
       "      <td>1969-12-31</td>\n",
       "      <td>87.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>211</td>\n",
       "      <td>66.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>65</td>\n",
       "      <td>malasya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>Hanya Rindu</td>\n",
       "      <td>Andmesh</td>\n",
       "      <td>indonesian pop</td>\n",
       "      <td>2019</td>\n",
       "      <td>1969-12-31</td>\n",
       "      <td>179.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>252</td>\n",
       "      <td>89.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65</td>\n",
       "      <td>malasya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                       Track Name          Artist  \\\n",
       "0             1                     Dance Monkey     Tones and I   \n",
       "1             2                          ROXANNE  Arizona Zervas   \n",
       "2             3                         Memories        Maroon 5   \n",
       "3             4                          Circles     Post Malone   \n",
       "4             5  All I Want for Christmas Is You    Mariah Carey   \n",
       "..          ...                              ...             ...   \n",
       "995         996                         Feelings            Lauv   \n",
       "996         997               Mimpi (feat. Alif)        K-Clique   \n",
       "997         998                 Cinta Luar Biasa         Andmesh   \n",
       "998         999                        Haa Tepok         MeerFly   \n",
       "999        1000                      Hanya Rindu         Andmesh   \n",
       "\n",
       "             top genre  year       added    bpm  nrgy  dnce    dB  live   val  \\\n",
       "0       australian pop  2019  1969-12-31   98.0  59.0  82.0  -6.0  15.0  51.0   \n",
       "1              pop rap  2019  1969-12-31  117.0  60.0  62.0  -6.0  46.0  46.0   \n",
       "2                  pop  2019  1969-12-31   91.0  32.0  76.0  -7.0   8.0  57.0   \n",
       "3              dfw rap  2019  1969-12-31  120.0  76.0  70.0  -3.0   9.0  55.0   \n",
       "4            dance pop  1994  1969-12-31  150.0  63.0  34.0  -7.0   7.0  35.0   \n",
       "..                 ...   ...         ...    ...   ...   ...   ...   ...   ...   \n",
       "995                pop  2019  1969-12-31  103.0  47.0  69.0  -7.0  10.0  25.0   \n",
       "996    malaysian indie  2019  1969-12-31  150.0  73.0  83.0  -7.0  10.0  87.0   \n",
       "997     indonesian pop  2019  1969-12-31  136.0  23.0  58.0 -12.0  10.0  32.0   \n",
       "998  malaysian hip hop  2019  1969-12-31   87.0  50.0  85.0 -12.0  15.0  68.0   \n",
       "999     indonesian pop  2019  1969-12-31  179.0  16.0  28.0 -12.0  11.0  20.0   \n",
       "\n",
       "     dur  acous  spch  pop  country  \n",
       "0    209   69.0   9.0  100    world  \n",
       "1    164    5.0  15.0   99    world  \n",
       "2    189   84.0   5.0   99    world  \n",
       "3    215   19.0   4.0   99    world  \n",
       "4    241   16.0   4.0   98    world  \n",
       "..   ...    ...   ...  ...      ...  \n",
       "995  190    9.0   4.0   73  malasya  \n",
       "996  253   53.0  29.0   66  malasya  \n",
       "997  256   81.0   3.0   66  malasya  \n",
       "998  211   66.0  31.0   65  malasya  \n",
       "999  252   89.0   3.0   65  malasya  \n",
       "\n",
       "[1000 rows x 17 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "allgenre = pd.read_csv('Data/genre_by_country/top50country3.csv')\n",
    "\n",
    "\n",
    "allgenre = allgenre.rename(columns={\"title\" : \"Track Name\", \"artist\" : \"Artist\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.read_csv('Data/all_weekly_charts/all_weekly_masterfile_features.csv')\n",
    "\n",
    "all_merged = pd.merge(features_df, allgenre,\n",
    "                        how=\"left\", on=[\"Track Name\", \"Artist\"])\n",
    "\n",
    "all_merged.to_csv('Data/all_weekly_charts/all_weekly_masterfile_features.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "region_groups = left_merged.groupby('Region').agg({\n",
    "    'Streams' : 'sum',\n",
    "    'Track Name' : 'count',\n",
    "    'Artist' : 'count',\n",
    "    'acousticness' : 'mean',\n",
    "    'danceability' : 'mean',\n",
    "    'duration_ms' : 'mean',\n",
    "    'energy' : 'mean',\n",
    "    'key' : lambda x : x.value_counts().index[0],\n",
    "    'liveness' : 'mean',\n",
    "    'instrumentalness' : 'mean',\n",
    "    'loudness' : 'mean',\n",
    "    'mode' : 'mean',\n",
    "    'popularity' : 'mean',\n",
    "    'danceability' : 'mean',\n",
    "    'energy' : 'mean',\n",
    "    'mode' : 'mean',\n",
    "    'valence' : 'mean',\n",
    "    'tempo' : 'mean',\n",
    "    'speechiness' : 'mean',\n",
    "    'danceability' : 'mean',\n",
    "    \n",
    "})\n",
    "\n",
    "# region_groups.to_csv('Data/all_weekly_charts/group_all_regions_masterfile.csv')\n",
    "\n",
    "region_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_merged.groupby('Region').agg({'key' : lambda x : x.value_counts().index[0]})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "argentina =  left_merged.loc[left_merged[\"Region\"] == 'Argentina']\n",
    "\n",
    "argentina_group= argentina.groupby('Region').agg({\n",
    "    'Streams' : 'sum',\n",
    "    'Track Name' : 'count',\n",
    "    'Artist' : 'count',\n",
    "    'acousticness' : 'mean',\n",
    "    'danceability' : 'mean',\n",
    "    'duration_ms' : 'mean',\n",
    "    'energy' : 'mean',\n",
    "    'key' : 'count',\n",
    "    'liveness' : 'mean',\n",
    "    'instrumentalness' : 'mean',\n",
    "    'loudness' : 'mean',\n",
    "    'mode' : 'mean',\n",
    "    'popularity' : 'mean',\n",
    "    'danceability' : 'mean',\n",
    "    'energy' : 'mean',\n",
    "    'mode' : 'mean',\n",
    "    'valence' : 'mean',\n",
    "    'tempo' : 'mean',\n",
    "    'speechiness' : 'mean',\n",
    "    'danceability' : 'mean',\n",
    "    \n",
    "})\n",
    "\n",
    "argentina_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///weekly_charts.sqlite', echo=False)\n",
    "\n",
    "left_merged.to_sql('all_weekly_charts_features', con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
