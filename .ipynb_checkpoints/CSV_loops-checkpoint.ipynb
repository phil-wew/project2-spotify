{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite://', echo=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_features = pd.read_csv(r'Data/all_songs_data/data.csv')\n",
    "\n",
    "track_features = track_features.rename(columns={\"name\" : \"Track Name\", \"artists\" : \"Artist\"})\n",
    "\n",
    "track_features.loc[:,'Artist'] = track_features.Artist.map(lambda x: x.replace(\"['\", \"\").replace(\"']\",\"\"))\n",
    "                                                \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>Artist</th>\n",
       "      <th>danceability</th>\n",
       "      <th>duration_ms</th>\n",
       "      <th>energy</th>\n",
       "      <th>explicit</th>\n",
       "      <th>id</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>key</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>Track Name</th>\n",
       "      <th>popularity</th>\n",
       "      <th>release_date</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>valence</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.9950</td>\n",
       "      <td>Carl Woitschach</td>\n",
       "      <td>0.708</td>\n",
       "      <td>158648</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0</td>\n",
       "      <td>6KbQ3uYMLKb5jDxLF7wYDD</td>\n",
       "      <td>0.563000</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>-12.428</td>\n",
       "      <td>1</td>\n",
       "      <td>Singende Bataillone 1. Teil</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>118.469</td>\n",
       "      <td>0.7790</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.9940</td>\n",
       "      <td>Robert Schumann', 'Vladimir Horowitz</td>\n",
       "      <td>0.379</td>\n",
       "      <td>282133</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0</td>\n",
       "      <td>6KuQTIu1KoTTkLXKrwlLPV</td>\n",
       "      <td>0.901000</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0763</td>\n",
       "      <td>-28.454</td>\n",
       "      <td>1</td>\n",
       "      <td>Fantasiestücke, Op. 111: Più tosto lento</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>83.972</td>\n",
       "      <td>0.0767</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.6040</td>\n",
       "      <td>Seweryn Goszczyński</td>\n",
       "      <td>0.749</td>\n",
       "      <td>104300</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0</td>\n",
       "      <td>6L63VW0PibdM1HDSBoqnoM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>-19.924</td>\n",
       "      <td>0</td>\n",
       "      <td>Chapter 1.18 - Zamek kaniowski</td>\n",
       "      <td>0</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.9290</td>\n",
       "      <td>107.177</td>\n",
       "      <td>0.8800</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.9950</td>\n",
       "      <td>Francisco Canaro</td>\n",
       "      <td>0.781</td>\n",
       "      <td>180760</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0</td>\n",
       "      <td>6M94FkXd15sOAOQYRnWPN8</td>\n",
       "      <td>0.887000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-14.734</td>\n",
       "      <td>0</td>\n",
       "      <td>Bebamos Juntos - Instrumental (Remasterizado)</td>\n",
       "      <td>0</td>\n",
       "      <td>1928-09-25</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>108.003</td>\n",
       "      <td>0.7200</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.9900</td>\n",
       "      <td>Frédéric Chopin', 'Vladimir Horowitz</td>\n",
       "      <td>0.210</td>\n",
       "      <td>687733</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0</td>\n",
       "      <td>6N6tiFZ9vLTSOIxkj8qKrd</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>-16.829</td>\n",
       "      <td>1</td>\n",
       "      <td>Polonaise-Fantaisie in A-Flat Major, Op. 61</td>\n",
       "      <td>1</td>\n",
       "      <td>1928</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>62.149</td>\n",
       "      <td>0.0693</td>\n",
       "      <td>1928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169904</th>\n",
       "      <td>0.1730</td>\n",
       "      <td>DripReport', 'Tyga</td>\n",
       "      <td>0.875</td>\n",
       "      <td>163800</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>1</td>\n",
       "      <td>4KppkflX7I3vJQk7urOJaS</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0891</td>\n",
       "      <td>-7.461</td>\n",
       "      <td>1</td>\n",
       "      <td>Skechers (feat. Tyga) - Remix</td>\n",
       "      <td>75</td>\n",
       "      <td>2020-05-15</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>100.012</td>\n",
       "      <td>0.3060</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169905</th>\n",
       "      <td>0.0167</td>\n",
       "      <td>Leon Bridges', 'Terrace Martin</td>\n",
       "      <td>0.719</td>\n",
       "      <td>167468</td>\n",
       "      <td>0.3850</td>\n",
       "      <td>0</td>\n",
       "      <td>1ehhGlTvjtHo2e4xJFB0SZ</td>\n",
       "      <td>0.031300</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>-10.907</td>\n",
       "      <td>1</td>\n",
       "      <td>Sweeter (feat. Terrace Martin)</td>\n",
       "      <td>64</td>\n",
       "      <td>2020-06-08</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>128.000</td>\n",
       "      <td>0.2700</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169906</th>\n",
       "      <td>0.5380</td>\n",
       "      <td>Kygo', 'Oh Wonder</td>\n",
       "      <td>0.514</td>\n",
       "      <td>180700</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0</td>\n",
       "      <td>52eycxprLhK3lPcRLbQiVk</td>\n",
       "      <td>0.002330</td>\n",
       "      <td>7</td>\n",
       "      <td>0.1080</td>\n",
       "      <td>-9.332</td>\n",
       "      <td>1</td>\n",
       "      <td>How Would I Know</td>\n",
       "      <td>70</td>\n",
       "      <td>2020-05-29</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>123.700</td>\n",
       "      <td>0.1530</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169907</th>\n",
       "      <td>0.0714</td>\n",
       "      <td>Cash Cash', 'Andy Grammer</td>\n",
       "      <td>0.646</td>\n",
       "      <td>167308</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0</td>\n",
       "      <td>3wYOGJYD31sLRmBgCvWxa4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>-2.557</td>\n",
       "      <td>1</td>\n",
       "      <td>I Found You</td>\n",
       "      <td>70</td>\n",
       "      <td>2020-02-28</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>129.916</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169908</th>\n",
       "      <td>0.1090</td>\n",
       "      <td>Ingrid Andress</td>\n",
       "      <td>0.512</td>\n",
       "      <td>214787</td>\n",
       "      <td>0.4280</td>\n",
       "      <td>0</td>\n",
       "      <td>60RFlt48hm0l4Fu0JoccOl</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>-7.387</td>\n",
       "      <td>1</td>\n",
       "      <td>More Hearts Than Mine</td>\n",
       "      <td>65</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>80.588</td>\n",
       "      <td>0.3660</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>169909 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        acousticness                                Artist  danceability  \\\n",
       "0             0.9950                       Carl Woitschach         0.708   \n",
       "1             0.9940  Robert Schumann', 'Vladimir Horowitz         0.379   \n",
       "2             0.6040                   Seweryn Goszczyński         0.749   \n",
       "3             0.9950                      Francisco Canaro         0.781   \n",
       "4             0.9900  Frédéric Chopin', 'Vladimir Horowitz         0.210   \n",
       "...              ...                                   ...           ...   \n",
       "169904        0.1730                    DripReport', 'Tyga         0.875   \n",
       "169905        0.0167        Leon Bridges', 'Terrace Martin         0.719   \n",
       "169906        0.5380                     Kygo', 'Oh Wonder         0.514   \n",
       "169907        0.0714             Cash Cash', 'Andy Grammer         0.646   \n",
       "169908        0.1090                        Ingrid Andress         0.512   \n",
       "\n",
       "        duration_ms  energy  explicit                      id  \\\n",
       "0            158648  0.1950         0  6KbQ3uYMLKb5jDxLF7wYDD   \n",
       "1            282133  0.0135         0  6KuQTIu1KoTTkLXKrwlLPV   \n",
       "2            104300  0.2200         0  6L63VW0PibdM1HDSBoqnoM   \n",
       "3            180760  0.1300         0  6M94FkXd15sOAOQYRnWPN8   \n",
       "4            687733  0.2040         0  6N6tiFZ9vLTSOIxkj8qKrd   \n",
       "...             ...     ...       ...                     ...   \n",
       "169904       163800  0.4430         1  4KppkflX7I3vJQk7urOJaS   \n",
       "169905       167468  0.3850         0  1ehhGlTvjtHo2e4xJFB0SZ   \n",
       "169906       180700  0.5390         0  52eycxprLhK3lPcRLbQiVk   \n",
       "169907       167308  0.7610         0  3wYOGJYD31sLRmBgCvWxa4   \n",
       "169908       214787  0.4280         0  60RFlt48hm0l4Fu0JoccOl   \n",
       "\n",
       "        instrumentalness  key  liveness  loudness  mode  \\\n",
       "0               0.563000   10    0.1510   -12.428     1   \n",
       "1               0.901000    8    0.0763   -28.454     1   \n",
       "2               0.000000    5    0.1190   -19.924     0   \n",
       "3               0.887000    1    0.1110   -14.734     0   \n",
       "4               0.908000   11    0.0980   -16.829     1   \n",
       "...                  ...  ...       ...       ...   ...   \n",
       "169904          0.000032    1    0.0891    -7.461     1   \n",
       "169905          0.031300    8    0.1110   -10.907     1   \n",
       "169906          0.002330    7    0.1080    -9.332     1   \n",
       "169907          0.000000    1    0.2220    -2.557     1   \n",
       "169908          0.000000    0    0.1050    -7.387     1   \n",
       "\n",
       "                                           Track Name  popularity  \\\n",
       "0                         Singende Bataillone 1. Teil           0   \n",
       "1            Fantasiestücke, Op. 111: Più tosto lento           0   \n",
       "2                      Chapter 1.18 - Zamek kaniowski           0   \n",
       "3       Bebamos Juntos - Instrumental (Remasterizado)           0   \n",
       "4         Polonaise-Fantaisie in A-Flat Major, Op. 61           1   \n",
       "...                                               ...         ...   \n",
       "169904                  Skechers (feat. Tyga) - Remix          75   \n",
       "169905                 Sweeter (feat. Terrace Martin)          64   \n",
       "169906                               How Would I Know          70   \n",
       "169907                                    I Found You          70   \n",
       "169908                          More Hearts Than Mine          65   \n",
       "\n",
       "       release_date  speechiness    tempo  valence  year  \n",
       "0              1928       0.0506  118.469   0.7790  1928  \n",
       "1              1928       0.0462   83.972   0.0767  1928  \n",
       "2              1928       0.9290  107.177   0.8800  1928  \n",
       "3        1928-09-25       0.0926  108.003   0.7200  1928  \n",
       "4              1928       0.0424   62.149   0.0693  1928  \n",
       "...             ...          ...      ...      ...   ...  \n",
       "169904   2020-05-15       0.1430  100.012   0.3060  2020  \n",
       "169905   2020-06-08       0.0403  128.000   0.2700  2020  \n",
       "169906   2020-05-29       0.1050  123.700   0.1530  2020  \n",
       "169907   2020-02-28       0.0385  129.916   0.4720  2020  \n",
       "169908   2020-03-27       0.0271   80.588   0.3660  2020  \n",
       "\n",
       "[169909 rows x 19 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "track_features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['2', 'Old Town Road (feat. Billy Ray Cyrus) - Remix', 'Lil Nas X',\n",
      "       '36616698', 'https://open.spotify.com/track/6u7jPi22kF8CTQ3rb9DHE7',\n",
      "       '2019-04-19', 'Global', '2019-04-19.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'I Don't Care (with Justin Bieber)', 'Ed Sheeran', '31405904',\n",
      "       'https://open.spotify.com/track/0hVXuCcriWRGvwMV1r5Yn9', '2019-07-26',\n",
      "       'Global', '2019-07-26.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Sucker', 'Jonas Brothers', '30872883',\n",
      "       'https://open.spotify.com/track/4y3OI86AEP6PQoDE6olYhO', '2019-03-15',\n",
      "       'Global', '2019-03-15.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'MIDDLE CHILD', 'J. Cole', '33187464',\n",
      "       'https://open.spotify.com/track/2JvzF1RMd7lE3KmFlsyZD8', '2019-02-01',\n",
      "       'Global', '2019-02-01.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Con Calma', 'Daddy Yankee', '29137725',\n",
      "       'https://open.spotify.com/track/5w9c2J52mkdntKOmRLeM2m', '2019-04-05',\n",
      "       'Global', '2019-04-05.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'All I Want for Christmas Is You', 'Mariah Carey', '45828931',\n",
      "       'https://open.spotify.com/track/0bYg9bo50gSsH3LtXe2SQn', '2019-12-27',\n",
      "       'Global', '2019-12-27.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'HIGHEST IN THE ROOM', 'Travis Scott', '32639894',\n",
      "       'https://open.spotify.com/track/3eekarcy7kvN4yt5ZFzltW', '2019-10-25',\n",
      "       'Global', '2019-10-25.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'ROXANNE', 'Arizona Zervas', '30315675',\n",
      "       'https://open.spotify.com/track/696DnlkuDOXcMAnKlTgXXK', '2019-12-13',\n",
      "       'Global', '2019-12-13.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Wow.', 'Post Malone', '29944242',\n",
      "       'https://open.spotify.com/track/6MWtB6iiXyIwun0YzU6DFP', '2019-01-18',\n",
      "       'Global', '2019-01-18.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Dance Monkey', 'Tones And I', '37248929',\n",
      "       'https://open.spotify.com/track/1rgnBhdG2JDFTbYkYRZAku', '2019-10-11',\n",
      "       'Global', '2019-10-11.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'ME! (feat. Brendon Urie of Panic! At The Disco)', 'Taylor Swift',\n",
      "       '37826059', 'https://open.spotify.com/track/4Sib57MmYGJzSvkW84jTwh',\n",
      "       '2019-05-03', 'Global', '2019-05-03.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'break up with your girlfriend, i'm bored', 'Ariana Grande',\n",
      "       '40862694', 'https://open.spotify.com/track/4kV4N9D1iKVxx1KLvtTpjS',\n",
      "       '2019-02-22', 'Global', '2019-02-22.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'bad guy', 'Billie Eilish', '37896855',\n",
      "       'https://open.spotify.com/track/2Fxmhks0bxGSBdJ92vM42m', '2019-06-07',\n",
      "       'Global', '2019-06-07.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Goodbyes (Feat. Young Thug)', 'Post Malone', '37067320',\n",
      "       'https://open.spotify.com/track/6vBdBCoOhKHiYDDOcorfNo', '2019-07-12',\n",
      "       'Global', '2019-07-12.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'ROXANNE', 'Arizona Zervas', '32668758',\n",
      "       'https://open.spotify.com/track/696DnlkuDOXcMAnKlTgXXK', '2019-12-20',\n",
      "       'Global', '2019-12-20.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Con Calma', 'Daddy Yankee', '30456817',\n",
      "       'https://open.spotify.com/track/5w9c2J52mkdntKOmRLeM2m', '2019-03-22',\n",
      "       'Global', '2019-03-22.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'bad guy', 'Billie Eilish', '41377841',\n",
      "       'https://open.spotify.com/track/2Fxmhks0bxGSBdJ92vM42m', '2019-05-17',\n",
      "       'Global', '2019-05-17.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Sunflower - Spider-Man: Into the Spider-Verse', 'Post Malone',\n",
      "       '33799389', 'https://open.spotify.com/track/3KkXRkHbMCARz0aVfEt68P',\n",
      "       '2019-01-25', 'Global', '2019-01-25.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Lover', 'Taylor Swift', '29990567',\n",
      "       'https://open.spotify.com/track/1dGr1c8CrMLDpV6mPbImSI', '2019-08-30',\n",
      "       'Global', '2019-08-30.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Lose You To Love Me', 'Selena Gomez', '34332985',\n",
      "       'https://open.spotify.com/track/1HfMVBKM75vxSfsQ5VefZ5', '2019-11-08',\n",
      "       'Global', '2019-11-08.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'HIGHEST IN THE ROOM', 'Travis Scott', '36969014',\n",
      "       'https://open.spotify.com/track/3eekarcy7kvN4yt5ZFzltW', '2019-10-18',\n",
      "       'Global', '2019-10-18.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'China', 'Anuel AA', '30684023',\n",
      "       'https://open.spotify.com/track/2ksOAxtIxY8yElEWw8RhgK', '2019-08-23',\n",
      "       'Global', '2019-08-23.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'I Don't Care (with Justin Bieber)', 'Ed Sheeran', '37834490',\n",
      "       'https://open.spotify.com/track/3HVWdVOQ0ZA45FuZGSfvns', '2019-06-28',\n",
      "       'Global', '2019-06-28.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'thank u, next', 'Ariana Grande', '29904412',\n",
      "       'https://open.spotify.com/track/2rPE9A1vEgShuZxxzR2tZH', '2019-01-11',\n",
      "       'Global', '2019-01-11.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Dance Monkey', 'Tones And I', '46086874',\n",
      "       'https://open.spotify.com/track/1rgnBhdG2JDFTbYkYRZAku', '2019-11-01',\n",
      "       'Global', '2019-11-01.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Con Calma', 'Daddy Yankee', '31111446',\n",
      "       'https://open.spotify.com/track/5w9c2J52mkdntKOmRLeM2m', '2019-03-29',\n",
      "       'Global', '2019-03-29.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'break up with your girlfriend, i'm bored', 'Ariana Grande',\n",
      "       '54707620', 'https://open.spotify.com/track/4kV4N9D1iKVxx1KLvtTpjS',\n",
      "       '2019-02-15', 'Global', '2019-02-15.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'bad guy', 'Billie Eilish', '35389193',\n",
      "       'https://open.spotify.com/track/2Fxmhks0bxGSBdJ92vM42m', '2019-06-21',\n",
      "       'Global', '2019-06-21.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Sucker', 'Jonas Brothers', '34629196',\n",
      "       'https://open.spotify.com/track/4y3OI86AEP6PQoDE6olYhO', '2019-03-08',\n",
      "       'Global', '2019-03-08.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'I Don't Care (with Justin Bieber)', 'Ed Sheeran', '37315688',\n",
      "       'https://open.spotify.com/track/3HVWdVOQ0ZA45FuZGSfvns', '2019-07-05',\n",
      "       'Global', '2019-07-05.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'bad guy', 'Billie Eilish', '39674898',\n",
      "       'https://open.spotify.com/track/2Fxmhks0bxGSBdJ92vM42m', '2019-05-24',\n",
      "       'Global', '2019-05-24.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'break up with your girlfriend, i'm bored', 'Ariana Grande',\n",
      "       '33580067', 'https://open.spotify.com/track/4kV4N9D1iKVxx1KLvtTpjS',\n",
      "       '2019-03-01', 'Global', '2019-03-01.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'I Don't Care (with Justin Bieber)', 'Ed Sheeran', '38459324',\n",
      "       'https://open.spotify.com/track/0hVXuCcriWRGvwMV1r5Yn9', '2019-07-19',\n",
      "       'Global', '2019-07-19.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Señorita', 'Shawn Mendes', '42601173',\n",
      "       'https://open.spotify.com/track/6v3KW9xbzN5yKLt9YKDYA2', '2019-09-13',\n",
      "       'Global', '2019-09-13.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'everything i wanted', 'Billie Eilish', '40323676',\n",
      "       'https://open.spotify.com/track/3ZCTVFBt2Brf31RLEnCkWJ', '2019-11-22',\n",
      "       'Global', '2019-11-22.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'China', 'Anuel AA', '33436706',\n",
      "       'https://open.spotify.com/track/2ksOAxtIxY8yElEWw8RhgK', '2019-08-09',\n",
      "       'Global', '2019-08-09.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'China', 'Anuel AA', '31043931',\n",
      "       'https://open.spotify.com/track/2ksOAxtIxY8yElEWw8RhgK', '2019-08-02',\n",
      "       'Global', '2019-08-02.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Circles', 'Post Malone', '31127024',\n",
      "       'https://open.spotify.com/track/21jGcNKet2qwijlDFuPiPb', '2019-09-27',\n",
      "       'Global', '2019-09-27.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['2', 'Old Town Road (feat. Billy Ray Cyrus) - Remix', 'Lil Nas X',\n",
      "       '32205489', 'https://open.spotify.com/track/6u7jPi22kF8CTQ3rb9DHE7',\n",
      "       '2019-05-10', 'Global', '2019-05-10.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Old Town Road (feat. Billy Ray Cyrus) - Remix', 'Lil Nas X',\n",
      "       '33975090', 'https://open.spotify.com/track/6u7jPi22kF8CTQ3rb9DHE7',\n",
      "       '2019-04-26', 'Global', '2019-04-26.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'bad guy', 'Billie Eilish', '37285019',\n",
      "       'https://open.spotify.com/track/2Fxmhks0bxGSBdJ92vM42m', '2019-06-14',\n",
      "       'Global', '2019-06-14.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'ROXANNE', 'Arizona Zervas', '31871446',\n",
      "       'https://open.spotify.com/track/696DnlkuDOXcMAnKlTgXXK', '2019-11-29',\n",
      "       'Global', '2019-11-29.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Old Town Road (feat. Billy Ray Cyrus) - Remix', 'Lil Nas X',\n",
      "       '33777904', 'https://open.spotify.com/track/6u7jPi22kF8CTQ3rb9DHE7',\n",
      "       '2019-04-12', 'Global', '2019-04-12.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'ROXANNE', 'Arizona Zervas', '31485166',\n",
      "       'https://open.spotify.com/track/696DnlkuDOXcMAnKlTgXXK', '2019-12-06',\n",
      "       'Global', '2019-12-06.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Dance Monkey', 'Tones And I', '33013044',\n",
      "       'https://open.spotify.com/track/1rgnBhdG2JDFTbYkYRZAku', '2019-10-04',\n",
      "       'Global', '2019-10-04.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'China', 'Anuel AA', '32258902',\n",
      "       'https://open.spotify.com/track/2ksOAxtIxY8yElEWw8RhgK', '2019-08-16',\n",
      "       'Global', '2019-08-16.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Circles', 'Post Malone', '34872620',\n",
      "       'https://open.spotify.com/track/21jGcNKet2qwijlDFuPiPb', '2019-09-20',\n",
      "       'Global', '2019-09-20.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Memories', 'Maroon 5', '30217278',\n",
      "       'https://open.spotify.com/track/2b8fOow8UzyDFAE27YhOZM', '2019-11-15',\n",
      "       'Global', '2019-11-15.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Sunflower - Spider-Man: Into the Spider-Verse', 'Post Malone',\n",
      "       '30229896', 'https://open.spotify.com/track/3KkXRkHbMCARz0aVfEt68P',\n",
      "       '2019-01-04', 'Global', '2019-01-04.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'Circles', 'Post Malone', '32068232',\n",
      "       'https://open.spotify.com/track/4VginDwYTP2eaHJzO0QMjG', '2019-09-06',\n",
      "       'Global', '2019-09-06.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n",
      "Index(['2', 'bad guy', 'Billie Eilish', '39937921',\n",
      "       'https://open.spotify.com/track/2Fxmhks0bxGSBdJ92vM42m', '2019-05-31',\n",
      "       'Global', '2019-05-31.1', 'Global.1', 'Week', 'Region'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/global_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[35:45]\n",
    "    df = pd.read_csv('Data/global_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Global'\n",
    "    df.to_csv('Data/global_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(df.columns)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/global_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-ar-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-ar-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-ar-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-ar-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-ar-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-ar-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-ar-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-ar-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-ar-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-ar-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-ar-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-ar-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-ar-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-ar-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-ar-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-ar-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-ar-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-ar-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-ar-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-ar-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-ar-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-ar-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-ar-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-ar-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-ar-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-ar-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-ar-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-ar-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-ar-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-ar-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-ar-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-ar-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-ar-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-ar-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-ar-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-ar-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-ar-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-ar-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-ar-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-ar-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-ar-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-ar-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-ar-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-ar-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-ar-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-ar-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-ar-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-ar-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-ar-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-ar-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-ar-weekly-2019-11-08--2019-11-15.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/argentina_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/argentina_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Argentina'\n",
    "    df.to_csv('Data/argentina_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/argentina_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-at-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-at-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-at-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-at-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-at-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-at-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-at-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-at-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-at-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-at-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-at-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-at-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-at-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-at-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-at-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-at-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-at-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-at-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-at-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-at-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-at-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-at-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-at-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-at-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-at-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-at-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-at-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-at-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-at-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-at-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-at-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-at-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-at-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-at-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-at-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-at-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-at-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-at-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-at-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-at-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-at-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-at-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-at-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-at-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-at-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-at-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-at-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-at-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-at-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-at-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-at-weekly-2019-10-04--2019-10-11.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/austria_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/austria_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Austria'\n",
    "    df.to_csv('Data/austria_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/austria_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-be-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-be-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-be-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-be-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-be-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-be-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-be-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-be-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-be-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-be-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-be-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-be-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-be-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-be-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-be-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-be-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-be-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-be-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-be-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-be-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-be-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-be-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-be-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-be-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-be-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-be-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-be-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-be-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-be-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-be-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-be-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-be-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-be-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-be-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-be-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-be-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-be-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-be-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-be-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-be-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-be-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-be-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-be-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-be-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-be-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-be-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-be-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-be-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-be-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-be-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-be-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-be-weekly-2019-06-14--2019-06-21.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/belgium_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/belgium_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Belgium'\n",
    "    df.to_csv('Data/belgium_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/belgium_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-fr-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-fr-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-fr-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-fr-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-fr-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-fr-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-fr-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-fr-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-fr-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-fr-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-fr-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-fr-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-fr-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-fr-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-fr-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-fr-weekly-2019-04-05--2019-04-12.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/france_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/france_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'France'\n",
    "    df.to_csv('Data/france_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/france_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-gb-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-gb-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-gb-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-gb-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-gb-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-gb-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-gb-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-gb-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-gb-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-gb-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-gb-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-gb-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-gb-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-gb-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-gb-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-gb-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-gb-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-gb-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-gb-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-gb-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-gb-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-gb-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-gb-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-gb-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-gb-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-gb-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-gb-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-gb-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-gb-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-gb-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-gb-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-gb-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-gb-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-gb-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-gb-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-gb-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-gb-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-gb-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-gb-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-gb-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-gb-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-gb-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-gb-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-gb-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-gb-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-gb-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-gb-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-gb-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-gb-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-gb-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-gb-weekly-2019-09-13--2019-09-20.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/GB_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/GB_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Great Britain'\n",
    "    df.to_csv('Data/GB_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/GB_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-us-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-us-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-us-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-us-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-us-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-us-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-us-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-us-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-us-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-us-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-us-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-us-weekly-2019-09-27--2019-10-04.csv\n",
      "regional-us-weekly-2019-06-28--2019-07-05.csv\n",
      "regional-us-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-us-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-us-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-us-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-us-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-us-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-us-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-us-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-us-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-us-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-us-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-us-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-us-weekly-2019-06-21--2019-06-28.csv\n",
      "US_masterfile.csv\n",
      "regional-us-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-us-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-us-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-us-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-us-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-us-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-us-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-us-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-us-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-us-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-us-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-us-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-us-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-us-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-us-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-us-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-us-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-us-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-us-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-us-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-us-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-us-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-us-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-us-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-us-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-us-weekly-2019-12-20--2019-12-27.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/US_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/US_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'United States of America'\n",
    "    df.to_csv('Data/US_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/US_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regional-bg-weekly-2019-12-13--2019-12-20.csv\n",
      "regional-bg-weekly-2019-03-15--2019-03-22.csv\n",
      "regional-bg-weekly-2019-10-11--2019-10-18.csv\n",
      "regional-bg-weekly-2019-11-01--2019-11-08.csv\n",
      "regional-bg-weekly-2019-01-18--2019-01-25.csv\n",
      "regional-bg-weekly-2019-05-10--2019-05-17.csv\n",
      "regional-bg-weekly-2019-08-23--2019-08-30.csv\n",
      "regional-bg-weekly-2019-08-16--2019-08-23.csv\n",
      "regional-bg-weekly-2019-01-04--2019-01-11.csv\n",
      "regional-bg-weekly-2019-06-21--2019-06-28.csv\n",
      "regional-bg-weekly-2019-10-25--2019-11-01.csv\n",
      "regional-bg-weekly-2019-02-08--2019-02-15.csv\n",
      "regional-bg-weekly-2019-03-22--2019-03-29.csv\n",
      "regional-bg-weekly-2019-04-12--2019-04-19.csv\n",
      "regional-bg-weekly-2019-01-25--2019-02-01.csv\n",
      "regional-bg-weekly-2019-03-29--2019-04-05.csv\n",
      "regional-bg-weekly-2019-07-19--2019-07-26.csv\n",
      "regional-bg-weekly-2019-03-08--2019-03-15.csv\n",
      "regional-bg-weekly-2019-12-20--2019-12-27.csv\n",
      "regional-bg-weekly-2019-12-06--2019-12-13.csv\n",
      "regional-bg-weekly-2019-01-11--2019-01-18.csv\n",
      "regional-bg-weekly-2019-10-18--2019-10-25.csv\n",
      "regional-bg-weekly-2019-10-04--2019-10-11.csv\n",
      "regional-bg-weekly-2019-04-26--2019-05-03.csv\n",
      "regional-bg-weekly-2019-07-05--2019-07-12.csv\n",
      "regional-bg-weekly-2019-02-15--2019-02-22.csv\n",
      "regional-bg-weekly-2019-05-31--2019-06-07.csv\n",
      "regional-bg-weekly-2019-08-09--2019-08-16.csv\n",
      "regional-bg-weekly-2019-09-13--2019-09-20.csv\n",
      "regional-bg-weekly-2019-11-08--2019-11-15.csv\n",
      "regional-bg-weekly-2018-12-28--2019-01-04.csv\n",
      "regional-bg-weekly-2019-05-24--2019-05-31.csv\n",
      "regional-bg-weekly-2019-02-01--2019-02-08.csv\n",
      "regional-bg-weekly-2019-08-30--2019-09-06.csv\n",
      "regional-bg-weekly-2019-06-14--2019-06-21.csv\n",
      "regional-bg-weekly-2019-05-17--2019-05-24.csv\n",
      "regional-bg-weekly-2019-03-01--2019-03-08.csv\n",
      "regional-bg-weekly-2019-11-15--2019-11-22.csv\n",
      "regional-bg-weekly-2019-09-06--2019-09-13.csv\n",
      "regional-bg-weekly-2019-02-22--2019-03-01.csv\n",
      "regional-bg-weekly-2019-07-12--2019-07-19.csv\n",
      "regional-bg-weekly-2019-05-03--2019-05-10.csv\n",
      "regional-bg-weekly-2019-04-19--2019-04-26.csv\n",
      "regional-bg-weekly-2019-09-20--2019-09-27.csv\n",
      "regional-bg-weekly-2019-08-02--2019-08-09.csv\n",
      "regional-bg-weekly-2019-07-26--2019-08-02.csv\n",
      "regional-bg-weekly-2019-06-07--2019-06-14.csv\n",
      "regional-bg-weekly-2019-11-22--2019-11-29.csv\n",
      "regional-bg-weekly-2019-11-29--2019-12-06.csv\n",
      "regional-bg-weekly-2019-04-05--2019-04-12.csv\n",
      "regional-bg-weekly-2019-09-27--2019-10-04.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/bulgaria_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    date = i[31:41]\n",
    "    df = pd.read_csv('Data/bulgaria_weekly_charts/' + i, header = 1)\n",
    "    df.loc[:,'Week']= date\n",
    "    df.loc[:,'Region'] = 'Bulgaria'\n",
    "    df.to_csv('Data/bulgaria_weekly_charts/' + i, index = False)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/bulgaria_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_weekly_masterfile.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (1,2,4,5,9,12,13,18,23,28,29,30,32,33,35,36,37,39,40,42,43,44,46,47,49,54,58,60,62,64,66,68,70,72,74,76,77,79,81,83,84,86,87,89,91,93,94,96,97,99,101,103,104,106,107,108,109,111,112,114,116,118,120,121,122,124,125,127,129,131,133,135,136,138,140,142,144,146,148) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB_masterfile.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (1,2,4,5,9,10,12,13,14,15,17,18,20,21,24,25,30,35,37,38,39,41,42,44,45,47,48,50,51,53,54,56,58,60,62,64,66,67,68,70,71,72,73,75,76,78,80,82,84,86,87,88,90,91,93,94,96,97,99,100,101,103,104,106,108,110,111,112,114,115,117,118,119,121,122,123,125,126,128,130,132,133,134,136,137,139,141,143,145,147,149,151,153,155) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bulgaria_masterfile.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (4,5,9,10,12,13,18,23,24,25,27,28,33,35,36,37,39,40,42,43,45,47,49,51,53,55,58,59,61,62,64,66,68,70,72,73,74,76,77,79,81,83,84,85,87,88,90,92,94,96,98,100,102,104,106,107,109,111,113,115,117,119,121,123,125,127,129,131,133,135,137,139) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "belgium_masterfile.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (5,7,9,10,12,13,14,16,17,18,19,21,22,24,25,26,27,29,30,31,32,34,35,36,37,39,40,41,42,44,45,47,48,49,50,52,53,55,56,57,59,60,61,62,64,65,66,67,69,70,71,72,74,75,77,79,81,82,83,85,86,88,90,92,93,94,96,97,99,100,102,104,105,107,108,110,111,112,114,115,116,117,119,120,121,122,124,125,127,128,129,131,132,134,135,136,138,139,140,141,143,144,146,148,150,152,153,155,156,157,159,160,162,164,166,168,170,172,174,176,177,178,180,181) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "US_masterfile.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (1,2,4,5,9,10,12,13,18,19,20,22,23,25,26,27,29,30,32,34,36,41,42,43,45,46,48,50,55,57,59,61,63,65,67,69,70,71,73,74,75,76,78,79,81,83,85,86,87,89,90,92,94,96,97,98,100,101,103,105,107,109,111,113,115,117,119,121,123,125,127,128,130,131,133,135,137,139,141,143) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "argentina_masterfile.csv\n",
      "france_masterfile.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (5,7,11,12,14,15,16,17,18,20,21,22,23,24,26,27,28,29,30,32,33,34,35,36,38,39,40,41,42,44,45,46,51,52,53,56,57,58,63,64,65,66,68,69,70,71,72,74,75,76,81,82,83,85,86,87,89,90,92,93,95,96,97,99,100,101,102,104,105,106,107,108,110,111,112,114,115,116,117,119,120,121,123,124,125,126,128,129,130,132,133,135,136,138,139,141,142,144,145,147,148,150,151,153,154,156,157,158,159,161,162,163,164,166,167,168,170,171,173,174,175,177,178,179,181,182,184,185,187,188,190,191,193,194,196,197,199,200,202,203,205,206,207,208,210,211,212,214,215,217,218,219,221,222) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global_masterfile.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (5,10,14,15,20,21,22,24,25,26,29,30,31,33,34,35,37,38,39,41,42,43,45,46,50,51,52,54,55,56,58,59,60,61,63,64,66,67,68,70,71,73,74,75,77,78,79,81,82,84,86,88,89,91,92,93,95,96,98,100,101,103,104,105,106,108,109,110,111,113,114,116,117,118,120,121,122,124,125,127,128,129,131,132,133,135,136,138,140,141,142,144,145,146,148,149,150,151,153,154,156,158,160,162,163,165,166,167,169,170,171,173,174,176,177,179,181,183) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "austria_masterfile.csv\n"
     ]
    }
   ],
   "source": [
    "filenames = [i for i in os.listdir('Data/all_weekly_charts') if \".csv\" in i]\n",
    "alldata = pd.DataFrame()\n",
    "\n",
    "for i in filenames:\n",
    "    df = pd.read_csv('Data/all_weekly_charts/' + i)\n",
    "    \n",
    "    #Now accumulate to master file\n",
    "    alldata = pd.concat((alldata, df))\n",
    "    print(i)\n",
    "\n",
    "alldata.to_csv('Data/all_weekly_charts/all_weekly_masterfile.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PythonData/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (1,2,4,5,8,9,11,12,13,14,15,17,18,19,20,22,23,24,25,27,28,29,30,32,33,34,35,37,38,40,41,42,44,45,47,48,49,51,52,54,55,56,58,59,60,62,63,65,67,69,71,73,75,77,79,81,82,84,86,88,89,91,92,94,96,98,99,101,102,104,106,108,109,111,112,113,114,116,117,119,121,123,125,126,127,129,130,132,134,136,138,140,141,143,145,147,149,151,153,155,156,157,159,160,161,163,169,170,172,177,184,185,187,188,189,191,197,198,200,202,204,206,207,209,213,214,216,218,219,221,222,224,228,229,231,234,243,244,245,247,249,250,252,265,267,273,274,276,290,307,309,310,312,314,315,316,318,320,321,322,324,325,326,328,332,337,338,340,341,342,344,354,359,360,362,363,364,366,367,368,370,372,373,375,383,385,386,388,397,398,400,401,402,404,405,406,407,409,410,411,413,414,415,417,419,420,422,426,427,429,430,431,433,436,437,439,447,448,450,451,452,454,458,459,461,465,466,468,482,484,491,492,494,495,496,497,499,500,501,503,505,507,508,509,511,512,513,515,527,528,529,531,532,534,536,538,540,542,544,546,548,550,552,554,556,558,560,562,564,566,567,568,570,571,573,575,577,578,580,581,583,585,587,589,591,593,595,597,599,601,603,605,607,609,611,613,615,617,619,621,623,625,627,628,629,631,632,634,636,638,640,643,644,646,647,648,650,651,652,654,655,657,658,660,661,663,664,666,667,669,670,671,673,674,676,677,678,680,682,683,685,687,688,690,691,693,697,699,700,702,705,707,708,709,711,712,713,715,717,718,720,721,723,725,726,728,729,731,735,737,738,739,741,746,748,749,751,752,754) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'leaflet_merged' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-7bb1cbb29e45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         how=\"left\", on=[\"Track Name\", \"Artist\"])\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mleaflet_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'URL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'year'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mleft_merged\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data/all_weekly_charts/all_weekly_masterfile_features.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'leaflet_merged' is not defined"
     ]
    }
   ],
   "source": [
    "all_weekly = pd.read_csv('Data/all_weekly_charts/all_weekly_masterfile.csv')\n",
    "\n",
    "# #rename first so they have the same column names to join on\n",
    "left_merged = pd.merge(all_weekly, track_features,\n",
    "                        how=\"left\", on=[\"Track Name\", \"Artist\"])\n",
    "\n",
    "leaflet_merged.drop(columns=['URL', 'year'])\n",
    "\n",
    "left_merged.to_csv('Data/all_weekly_charts/all_weekly_masterfile_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite:///weekly_charts.sqlite', echo=False)\n",
    "\n",
    "left_merged.to_sql('all_weekly_charts_features', con=engine)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
